{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c430868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6f1f7-efb8-426c-b4e2-7a38e61e71e9",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8b5720-2e84-4bd5-8a7c-17116b57e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters\n",
    "batch_size = 32\n",
    "\n",
    "def apply_image_transformation(transformation_type=\"standard\", *args, **kwargs):\n",
    "    '''\n",
    "    Apply various image transformations based on the provided transformation_type.\n",
    "\n",
    "    Args:\n",
    "    transformation_type (str): The type of transformation to apply. Supported types are 'standard', 'resize', and 'channel'.\n",
    "    *args: Additional arguments based on the transformation type.\n",
    "    **kwargs: Additional keyword arguments for normalization parameters.\n",
    "\n",
    "    Returns:\n",
    "    transform: A composition of transformations to be applied to the input images.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If an unsupported transformation type is provided.\n",
    "\n",
    "    '''\n",
    "    if transformation_type == \"standard\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "        return transform\n",
    "\n",
    "    elif transformation_type == \"resize\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(args[0]),\n",
    "            transforms.CenterCrop(args[1]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(kwargs['mean'], kwargs['std'])\n",
    "        ])\n",
    "        return transform\n",
    "\n",
    "    elif transformation_type == \"channel\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(args[0]),\n",
    "            transforms.CenterCrop(args[1]),\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=kwargs['mean'], std=kwargs['std'])\n",
    "        ])\n",
    "        return transform\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transformation type. Supported types are 'normal', 'resize', and 'grayscale'.\")\n",
    "\n",
    "def create_loader(transform, batch_size=32):\n",
    "    '''\n",
    "    Create data loaders for training and testing using the provided transformation.\n",
    "\n",
    "    Args:\n",
    "    transform: The transformation to be applied to the dataset.\n",
    "    batch_size: The batch size of \n",
    "\n",
    "    Returns:\n",
    "    train_loader: DataLoader for the training dataset.\n",
    "    test_loader: DataLoader for the testing dataset.\n",
    "\n",
    "    This function imports the FashionMNIST dataset from the torchvision library and applies the provided transformation to the dataset. It then creates data loaders for both the training and testing datasets, considering the specified transformation and other default parameters such as the number of workers and batch size.\n",
    "    '''\n",
    "    # importing training and test sets from torchvision\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transform)\n",
    "    \n",
    "    # creating dataloaders\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, num_workers=2, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, num_workers=2, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f798e893-9f7d-48f2-8e7f-34b96a4c3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = apply_image_transformation('standard')\n",
    "basic_train_loader, basic_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('standard')\n",
    "vgg_train_loader, vgg_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('resize', 256, 224, mean=(0.1307,), std=(0.3081,))\n",
    "vgg_resize_train_loader, vgg_resize_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('channel', 256, 224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "vgg_channel_train_loader, vgg_channel_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('standard')\n",
    "resnet_train_loader, resnet_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('channel', 256, 224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "resnet_channel_train_loader, resnet_channel_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('standard')\n",
    "inception_train_loader, inception_test_loader = create_loader(transform)\n",
    "\n",
    "transform = apply_image_transformation('channel', 299, 299, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "inception_channel_train_loader, inception_channel_test_loader = create_loader(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc8b90-ddf0-4d69-bcc1-c8dc69222099",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba70826",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train(model, criterion, optimizer, num_epochs, train_loader, test_loader):\n",
    "  total_time_taken = 0.0\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "      # Get the inputs and labels\n",
    "      inputs, labels = data\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      # Zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(inputs)\n",
    "      if not torch.is_tensor(outputs):\n",
    "        outputs = outputs.logits\n",
    "\n",
    "      # Compute the loss\n",
    "      loss = criterion(outputs, labels)\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      # Backward pass and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Compute correct predictions\n",
    "      pred = outputs.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    total_time_taken += time.time() - start_time\n",
    "\n",
    "    # Compute train accuracy\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    test_acc = []\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(test_loader):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Compute correct predictions\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    # Compute test accuracy\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "    # Print statistics\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "  print(f'\\n\\nTotal Time Elapsed: {total_time_taken} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ef4fe-2ec7-40aa-a88b-d44c35815357",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Rather than using a simple convolution layer, each convolution layer is transformed into a 3 layer architecture\n",
    "- Convolution Layer\n",
    "- Batch Normalization Layer\n",
    "- Activation Layer (LeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd02978-a97e-4132-9583-29d6ec9a4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.basicconv2d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.basicconv2d(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11494bb4-9422-4956-b52d-dca7cdef1193",
   "metadata": {},
   "source": [
    "## Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6083ac-d021-43a8-b872-2ec7342f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BasicCNN, self).__init__()\n",
    "    self.conv1 = BasicConv2d(1, 32, 3) # 32 1x3x3 filters with stride 1, pad 0\n",
    "    '''\n",
    "    Output size = (28 - 3 + 2*0)/1 + 1 = 26\n",
    "    Output volume = 32x26x26\n",
    "    '''\n",
    "    self.pool = nn.MaxPool2d(2, 2) # 2x2 filter with stride 2\n",
    "    '''\n",
    "    Output size = (26 - 2)/2 + 1 = 13\n",
    "    Output volume = 32x13x13\n",
    "    '''\n",
    "    self.fc1 = nn.Linear(32 * 13 * 13, 100)\n",
    "    self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.conv1(x))\n",
    "    x = self.pool(x)\n",
    "    # Flatten the output of the last convolutional layer\n",
    "    x = x.view(-1, 32 * 13 * 13)\n",
    "    # Apply the fully connected layers with ReLU activation\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    # Apply the last fully connected layer with softmax activation\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a636689-1a62-4fc1-a771-d3cd6ea49211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:10<00:00, 183.54it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3895, Train Accuracy: 86.09%, Test Loss: 0.3606, Test Accuracy: 87.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:10<00:00, 187.35it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2682, Train Accuracy: 90.21%, Test Loss: 0.2744, Test Accuracy: 90.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 195.74it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2255, Train Accuracy: 91.72%, Test Loss: 0.2648, Test Accuracy: 90.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 193.37it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1976, Train Accuracy: 92.61%, Test Loss: 0.2784, Test Accuracy: 90.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 193.49it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1723, Train Accuracy: 93.62%, Test Loss: 0.2654, Test Accuracy: 91.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 194.67it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1518, Train Accuracy: 94.36%, Test Loss: 0.2802, Test Accuracy: 91.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 192.06it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1353, Train Accuracy: 95.06%, Test Loss: 0.2662, Test Accuracy: 91.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:10<00:00, 172.88it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1218, Train Accuracy: 95.45%, Test Loss: 0.3012, Test Accuracy: 91.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 190.41it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1094, Train Accuracy: 95.90%, Test Loss: 0.3200, Test Accuracy: 90.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 195.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0997, Train Accuracy: 96.26%, Test Loss: 0.3374, Test Accuracy: 91.41%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 98.87939119338989 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "BasicCNNModel = BasicCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(BasicCNNModel.parameters(), lr=learning_rate)\n",
    "\n",
    "train(BasicCNNModel, criterion, optimizer, num_epochs, basic_train_loader, basic_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b595ac3",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a98c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedVGG_A(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedVGG_A, self).__init__()\n",
    "    self.conv1_1 = BasicConv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "    self.conv1_2 = BasicConv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv2_1 = BasicConv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "    self.conv2_2 = BasicConv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv3_1 = BasicConv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "    self.conv3_2 = BasicConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "    self.conv3_3 = BasicConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv4_1 = BasicConv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "    self.conv4_2 = BasicConv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "    self.conv4_3 = BasicConv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(1 * 1 * 512, 64)\n",
    "    self.fc2 = nn.Linear(64, 64)\n",
    "    self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.conv1_1(x))\n",
    "    x = torch.relu(self.conv1_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv2_1(x))\n",
    "    x = torch.relu(self.conv2_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv3_1(x))\n",
    "    x = torch.relu(self.conv3_2(x))\n",
    "    x = torch.relu(self.conv3_3(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv4_1(x))\n",
    "    x = torch.relu(self.conv4_2(x))\n",
    "    x = torch.relu(self.conv4_3(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = x.view(-1, 1 * 1 * 512)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0724412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.55it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4477, Train Accuracy: 83.59%, Test Loss: 0.3525, Test Accuracy: 87.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:20<00:00, 93.46it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2765, Train Accuracy: 90.12%, Test Loss: 0.2682, Test Accuracy: 90.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 94.13it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2361, Train Accuracy: 91.68%, Test Loss: 0.2619, Test Accuracy: 90.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 94.62it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.2035, Train Accuracy: 92.85%, Test Loss: 0.2623, Test Accuracy: 90.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 95.56it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1779, Train Accuracy: 93.68%, Test Loss: 0.2159, Test Accuracy: 92.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.48it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1596, Train Accuracy: 94.27%, Test Loss: 0.2335, Test Accuracy: 92.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 95.32it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1382, Train Accuracy: 95.04%, Test Loss: 0.2079, Test Accuracy: 92.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.14it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1200, Train Accuracy: 95.67%, Test Loss: 0.2067, Test Accuracy: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.46it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1037, Train Accuracy: 96.30%, Test Loss: 0.2278, Test Accuracy: 92.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:20<00:00, 91.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0897, Train Accuracy: 96.81%, Test Loss: 0.2268, Test Accuracy: 92.97%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 197.37416219711304 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedVGGModel_A = ModifiedVGG_A().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedVGGModel_1.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedVGGModel_A, criterion, optimizer, num_epochs, vgg_train_loader, vgg_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b38898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedVGG_B(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedVGG_B, self).__init__()\n",
    "    self.conv1_1 = BasicConv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "    self.conv1_2 = BasicConv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv2_1 = BasicConv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "    self.conv2_2 = BasicConv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv3_1 = BasicConv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "    self.conv3_2 = BasicConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "    self.conv3_3 = BasicConv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(3 * 3 * 256, 256)\n",
    "    self.fc2 = nn.Linear(256, 256)\n",
    "    self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.conv1_1(x))\n",
    "    x = torch.relu(self.conv1_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv2_1(x))\n",
    "    x = torch.relu(self.conv2_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv3_1(x))\n",
    "    x = torch.relu(self.conv3_2(x))\n",
    "    x = torch.relu(self.conv3_3(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = x.view(-1, 3 * 3 * 256)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26276989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 112.59it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3913, Train Accuracy: 85.60%, Test Loss: 0.2799, Test Accuracy: 89.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 120.58it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2518, Train Accuracy: 90.83%, Test Loss: 0.2683, Test Accuracy: 90.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 120.51it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2117, Train Accuracy: 92.32%, Test Loss: 0.2409, Test Accuracy: 91.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 120.06it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1849, Train Accuracy: 93.36%, Test Loss: 0.2247, Test Accuracy: 92.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 119.93it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1590, Train Accuracy: 94.17%, Test Loss: 0.2315, Test Accuracy: 92.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.06it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1395, Train Accuracy: 94.84%, Test Loss: 0.2025, Test Accuracy: 92.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 116.78it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1180, Train Accuracy: 95.60%, Test Loss: 0.2249, Test Accuracy: 92.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 118.65it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1023, Train Accuracy: 96.29%, Test Loss: 0.2393, Test Accuracy: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 119.50it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0845, Train Accuracy: 96.85%, Test Loss: 0.2261, Test Accuracy: 92.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:16<00:00, 116.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0754, Train Accuracy: 97.25%, Test Loss: 0.2533, Test Accuracy: 93.08%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 158.5027265548706 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedVGGModel_B = ModifiedVGG_B().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedVGGModel_B.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedVGGModel_B, criterion, optimizer, num_epochs, vgg_train_loader, vgg_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc039b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedVGG_C(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedVGG_C, self).__init__()\n",
    "    self.conv1_1 = BasicConv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "    self.conv1_2 = BasicConv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "    self.conv2_1 = BasicConv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "    self.conv2_2 = BasicConv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(7 * 7 * 128, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 1024)\n",
    "    self.fc3 = nn.Linear(1024, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.conv1_1(x))\n",
    "    x = torch.relu(self.conv1_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = torch.relu(self.conv2_1(x))\n",
    "    x = torch.relu(self.conv2_2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = x.view(-1, 7 * 7 * 128)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b835e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 145.42it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3786, Train Accuracy: 86.53%, Test Loss: 0.2887, Test Accuracy: 89.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 131.53it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2416, Train Accuracy: 91.29%, Test Loss: 0.2589, Test Accuracy: 90.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 146.38it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.1986, Train Accuracy: 92.74%, Test Loss: 0.2351, Test Accuracy: 91.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 133.18it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1700, Train Accuracy: 93.68%, Test Loss: 0.2353, Test Accuracy: 92.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 128.67it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1413, Train Accuracy: 94.82%, Test Loss: 0.2194, Test Accuracy: 92.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 146.42it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1201, Train Accuracy: 95.52%, Test Loss: 0.2398, Test Accuracy: 92.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 146.65it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0992, Train Accuracy: 96.36%, Test Loss: 0.2502, Test Accuracy: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:13<00:00, 141.83it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0792, Train Accuracy: 97.06%, Test Loss: 0.2398, Test Accuracy: 92.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 146.10it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0665, Train Accuracy: 97.65%, Test Loss: 0.2698, Test Accuracy: 93.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 146.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0550, Train Accuracy: 98.06%, Test Loss: 0.2692, Test Accuracy: 93.00%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 133.07530236244202 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedVGGModel_C = ModifiedVGG_C().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedVGGModel_C.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedVGGModel_C, criterion, optimizer, num_epochs, vgg_train_loader, vgg_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df22431-8690-4d54-84b3-10c711fa25a1",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56e0d28-8287-4d9e-b047-3d438ae8691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block,  num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 2, stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365a323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet2(nn.Module):\n",
    "    def __init__(self, block,  num_classes=10):\n",
    "        super(ResNet2, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 2, stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out,4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d318d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:42<00:00, 44.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3766, Train Accuracy: 86.30%, Test Loss: 0.3068, Test Accuracy: 89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 77.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2539, Train Accuracy: 90.79%, Test Loss: 0.2429, Test Accuracy: 91.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 78.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2178, Train Accuracy: 92.04%, Test Loss: 0.2171, Test Accuracy: 92.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 77.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1896, Train Accuracy: 93.02%, Test Loss: 0.2216, Test Accuracy: 91.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 76.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1626, Train Accuracy: 94.02%, Test Loss: 0.2196, Test Accuracy: 92.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:23<00:00, 79.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1398, Train Accuracy: 94.79%, Test Loss: 0.2147, Test Accuracy: 92.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:23<00:00, 79.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1184, Train Accuracy: 95.60%, Test Loss: 0.2132, Test Accuracy: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:23<00:00, 78.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0977, Train Accuracy: 96.32%, Test Loss: 0.2087, Test Accuracy: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 77.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0782, Train Accuracy: 97.08%, Test Loss: 0.2463, Test Accuracy: 92.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:24<00:00, 78.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0642, Train Accuracy: 97.63%, Test Loss: 0.2328, Test Accuracy: 93.09%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 258.5876362323761 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ResNetModel_2 = ResNet2(BasicBlock, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ResNetModel_2.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ResNetModel_2, criterion, optimizer, num_epochs, resnet_train_loader, resnet_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b5f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.offset_conv = nn.Conv2d(in_planes, 18, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv1 = tv.ops.DeformConv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        offset = self.offset_conv(x)\n",
    "        out = self.conv1(x, offset)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = tv.ops.DeformConv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet3(nn.Module):\n",
    "    def __init__(self, block,  num_classes=10):\n",
    "        super(ResNet3, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, 2, stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba6e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:35<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9444, Train Accuracy: 65.76%, Test Loss: 0.9425, Test Accuracy: 66.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.7566, Train Accuracy: 72.55%, Test Loss: 0.6018, Test Accuracy: 78.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.6518, Train Accuracy: 76.43%, Test Loss: 0.6568, Test Accuracy: 76.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:35<00:00, 53.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.5722, Train Accuracy: 79.27%, Test Loss: 0.6241, Test Accuracy: 76.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.5121, Train Accuracy: 81.07%, Test Loss: 0.4641, Test Accuracy: 82.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:36<00:00, 51.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.4764, Train Accuracy: 82.48%, Test Loss: 0.4900, Test Accuracy: 82.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.4190, Train Accuracy: 84.69%, Test Loss: 0.4136, Test Accuracy: 84.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.3774, Train Accuracy: 86.11%, Test Loss: 0.3698, Test Accuracy: 86.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.3491, Train Accuracy: 86.99%, Test Loss: 0.3843, Test Accuracy: 85.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:34<00:00, 53.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.3341, Train Accuracy: 87.70%, Test Loss: 0.3471, Test Accuracy: 87.30%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 351.1620569229126 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ResNetModel_3 = ResNet3(BasicBlock, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ResNetModel_3.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ResNetModel_3, criterion, optimizer, num_epochs, resnet_train_loader, resnet_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfcfd41-5075-4b21-8277-07709a633ea7",
   "metadata": {},
   "source": [
    "# Inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24edd90d-445c-446e-8069-541e6de8b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Building Blocks\n",
    "class InceptionA(nn.Module):\n",
    "  def __init__(self, channels_in, pool_channels):\n",
    "    super(InceptionA, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 64, 1, stride=1, padding=0)\n",
    "    self.branch5x5 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 48, 1, stride=1, padding=0),\n",
    "        BasicConv2d(48, 64, 5, stride=1, padding=2)\n",
    "    )\n",
    "    self.branch3x3dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 64, 1, stride=1, padding=0),\n",
    "        BasicConv2d(64, 96, 3, stride=1, padding=1),\n",
    "        BasicConv2d(96, 96, 3, stride=1, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, pool_channels, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch1x1(x), self.branch5x5(x), self.branch3x3dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 64 + 64 + 96 + pool_channels\n",
    "\n",
    "class InceptionA_Reduction(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionA_Reduction, self).__init__()\n",
    "    self.branch3x3 = BasicConv2d(channels_in, 384, 3, stride=2, padding=1)\n",
    "    self.branch3x3dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 64, 1, padding=0),\n",
    "        BasicConv2d(64, 96, 3, padding=1),\n",
    "        BasicConv2d(96, 96, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch3x3(x), self.branch3x3dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 384 + 96 + channels_in\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "  def __init__(self, channels_in, channels_7x7):\n",
    "    super(InceptionB, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 192, 1, stride=1, padding=0)\n",
    "    self.branch7x7 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, channels_7x7, 1, stride=1, padding=0),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, 192, (1, 7), stride=1, padding=(0, 3))\n",
    "    )\n",
    "    self.branch7x7dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, channels_7x7, 1, stride=1, padding=0),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (1, 7), stride=1, padding=(0, 3)),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, 192, (1, 7), stride=1, padding=(0, 3))\n",
    "    )\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, 192, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch1x1(x), self.branch7x7(x), self.branch7x7dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 192 + 192 + 192 + 192 = 768 channels\n",
    "\n",
    "class InceptionB_Reduction(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionB_Reduction, self).__init__()\n",
    "    self.branch3x3 = nn.Sequential(\n",
    "      BasicConv2d(channels_in, 192, 1, stride=1, padding=0),\n",
    "      BasicConv2d(192, 320, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch7x7x3 = nn.Sequential(\n",
    "      BasicConv2d(channels_in, 192, 1, stride=1, padding=0),\n",
    "      BasicConv2d(192, 192, (1, 7), stride=1, padding=(0, 3)),\n",
    "      BasicConv2d(192, 192, (7, 1), stride=1, padding=(3, 0)),\n",
    "      BasicConv2d(192, 192, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch3x3(x), self.branch7x7x3(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 320+ 192 + channels_in\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionC, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 320, 1, stride=1, padding=0)\n",
    "\n",
    "    self.branch3x3_1 = BasicConv2d(channels_in, 384, 1, stride=1, padding=0)\n",
    "    self.branch3x3_2a = BasicConv2d(384, 384, (1, 3), stride=1, padding=(0, 1))\n",
    "    self.branch3x3_2b = BasicConv2d(384, 384, (3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "    self.branch3x3dbl_1 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 448, 1, stride=1, padding=0),\n",
    "        BasicConv2d(448, 384, 3, stride=1, padding=1)\n",
    "    )\n",
    "    self.branch3x3dbl_2a = BasicConv2d(384, 384, (1, 3), stride=1, padding=(0, 1))\n",
    "    self.branch3x3dbl_2b = BasicConv2d(384, 384, (3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, 192, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    branch1x1 = self.branch1x1(x)\n",
    "\n",
    "    branch3x3 = self.branch3x3_1(x)\n",
    "    branch3x3 = torch.cat([self.branch3x3_2a(branch3x3), self.branch3x3_2b(branch3x3)], 1)\n",
    "\n",
    "    branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "    branch3x3dbl = torch.cat([self.branch3x3dbl_2a(branch3x3dbl), self.branch3x3dbl_2b(branch3x3dbl)], 1)\n",
    "\n",
    "    branch_pool = self.branch_pool(x)\n",
    "\n",
    "    outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "    return torch.cat(outputs, 1)  # 320 + 768 + 768 + 192 = 2048 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c15fcfa-17b5-4928-9b15-4ccfa3215908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedInception_A(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedInception_A, self).__init__()\n",
    "    self.in_block = nn.Sequential(\n",
    "      BasicConv2d(1, 32, 3, stride=2, padding=0), # 15x15x32\n",
    "      BasicConv2d(32, 64, 3, stride=1, padding=0), # 13x13x32\n",
    "      BasicConv2d(64, 64, 3, stride=1, padding=1), # 13x13x64\n",
    "      nn.MaxPool2d(kernel_size=3, stride=2), # 6x6x64\n",
    "    )\n",
    "    self.mix_block = nn.Sequential(\n",
    "      InceptionA(64, 32),\n",
    "      InceptionA(256, 64),\n",
    "      InceptionA_Reduction(288),\n",
    "      InceptionB(768, 128),\n",
    "      InceptionB(768, 160),\n",
    "      InceptionB(768, 192),\n",
    "      InceptionB_Reduction(768),\n",
    "      InceptionC(1280),\n",
    "      InceptionC(2048),\n",
    "    )\n",
    "    self.out_block = nn.Sequential(\n",
    "      nn.AdaptiveAvgPool2d(1),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.in_block(x)\n",
    "    x = self.mix_block(x)\n",
    "    x = self.out_block(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06b1746c-e01e-463d-bf66-382f934764aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:27<00:00, 21.36it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6057, Train Accuracy: 77.96%, Test Loss: 0.4125, Test Accuracy: 85.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:28<00:00, 21.26it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3783, Train Accuracy: 86.69%, Test Loss: 0.3521, Test Accuracy: 87.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 21.01it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.3215, Train Accuracy: 88.64%, Test Loss: 0.3133, Test Accuracy: 89.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:31<00:00, 20.45it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.2875, Train Accuracy: 89.81%, Test Loss: 0.2870, Test Accuracy: 90.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:31<00:00, 20.55it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.2528, Train Accuracy: 90.98%, Test Loss: 0.2805, Test Accuracy: 90.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:30<00:00, 20.79it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.2307, Train Accuracy: 91.74%, Test Loss: 0.2514, Test Accuracy: 91.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.94it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.2086, Train Accuracy: 92.45%, Test Loss: 0.2813, Test Accuracy: 90.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:28<00:00, 21.12it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1885, Train Accuracy: 93.26%, Test Loss: 0.2871, Test Accuracy: 90.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:28<00:00, 21.27it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1709, Train Accuracy: 93.77%, Test Loss: 0.2524, Test Accuracy: 91.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.1527, Train Accuracy: 94.46%, Test Loss: 0.2537, Test Accuracy: 91.74%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 894.1422131061554 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedInceptionModel_A = ModifiedInception_A().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedInceptionModel_A.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedInceptionModel_A, criterion, optimizer, num_epochs, inception_train_loader, inception_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc2d002b-c7b5-4d51-8ba9-c6ab2e81eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedInception_B(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedInception_B, self).__init__()\n",
    "    self.in_block = nn.Sequential(\n",
    "      BasicConv2d(1, 32, 3, stride=2, padding=0), # 15x15x32\n",
    "      BasicConv2d(32, 64, 3, stride=1, padding=0), # 13x13x32\n",
    "      BasicConv2d(64, 64, 3, stride=1, padding=1), # 13x13x64\n",
    "      nn.MaxPool2d(kernel_size=3, stride=2), # 6x6x64\n",
    "    )\n",
    "    self.mix_block = nn.Sequential(\n",
    "      InceptionA(64, 64),\n",
    "      InceptionA_Reduction(288),\n",
    "      InceptionB(768, 128),\n",
    "      InceptionB(768, 192),\n",
    "      InceptionB_Reduction(768),\n",
    "      InceptionC(1280),\n",
    "    )\n",
    "    self.out_block = nn.Sequential(\n",
    "      nn.AdaptiveAvgPool2d(1),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.in_block(x)\n",
    "    x = self.mix_block(x)\n",
    "    x = self.out_block(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eee393d3-0e5e-4b03-8d30-f07bef8a6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:13<00:00, 25.52it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.5388, Train Accuracy: 80.66%, Test Loss: 0.3790, Test Accuracy: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:13<00:00, 25.59it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.3469, Train Accuracy: 87.56%, Test Loss: 0.3489, Test Accuracy: 87.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.15it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2948, Train Accuracy: 89.21%, Test Loss: 0.2778, Test Accuracy: 89.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:12<00:00, 25.88it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.2590, Train Accuracy: 90.58%, Test Loss: 0.2864, Test Accuracy: 89.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:10<00:00, 26.49it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.2379, Train Accuracy: 91.40%, Test Loss: 0.2878, Test Accuracy: 89.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.11it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.2108, Train Accuracy: 92.27%, Test Loss: 0.2703, Test Accuracy: 90.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.39it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1911, Train Accuracy: 92.93%, Test Loss: 0.2505, Test Accuracy: 91.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:09<00:00, 26.95it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1717, Train Accuracy: 93.72%, Test Loss: 0.2552, Test Accuracy: 91.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:10<00:00, 26.74it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.1604, Train Accuracy: 94.24%, Test Loss: 0.2531, Test Accuracy: 91.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:11<00:00, 26.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.1367, Train Accuracy: 94.97%, Test Loss: 0.2523, Test Accuracy: 91.42%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 715.276772737503 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedInceptionModel_B = ModifiedInception_B().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedInceptionModel_B.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedInceptionModel_B, criterion, optimizer, num_epochs, inception_train_loader, inception_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a503ed9-f9b8-4e4b-b6fd-f04d36229875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Building Blocks\n",
    "class InceptionA(nn.Module):\n",
    "  def __init__(self, channels_in, pool_channels):\n",
    "    super(InceptionA, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 32, 1, stride=1, padding=0)\n",
    "    self.branch5x5 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 24, 1, stride=1, padding=0),\n",
    "        BasicConv2d(24, 32, 5, stride=1, padding=2)\n",
    "    )\n",
    "    self.branch3x3dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 32, 1, stride=1, padding=0),\n",
    "        BasicConv2d(32, 48, 3, stride=1, padding=1),\n",
    "        BasicConv2d(48, 48, 3, stride=1, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, pool_channels, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch1x1(x), self.branch5x5(x), self.branch3x3dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 32 + 32 + 48 + pool_channels\n",
    "\n",
    "class InceptionA_Reduction(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionA_Reduction, self).__init__()\n",
    "    self.branch3x3 = BasicConv2d(channels_in, 192, 3, stride=2, padding=1)\n",
    "    self.branch3x3dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 32, 1, padding=0),\n",
    "        BasicConv2d(32, 48, 3, padding=1),\n",
    "        BasicConv2d(48, 48, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch3x3(x), self.branch3x3dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 192 + 48 + channels_in\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "  def __init__(self, channels_in, channels_7x7):\n",
    "    super(InceptionB, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 96, 1, stride=1, padding=0)\n",
    "    self.branch7x7 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, channels_7x7, 1, stride=1, padding=0),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, 96, (1, 7), stride=1, padding=(0, 3))\n",
    "    )\n",
    "    self.branch7x7dbl = nn.Sequential(\n",
    "        BasicConv2d(channels_in, channels_7x7, 1, stride=1, padding=0),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (1, 7), stride=1, padding=(0, 3)),\n",
    "        BasicConv2d(channels_7x7, channels_7x7, (7, 1), stride=1, padding=(3, 0)),\n",
    "        BasicConv2d(channels_7x7, 96, (1, 7), stride=1, padding=(0, 3))\n",
    "    )\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, 96, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch1x1(x), self.branch7x7(x), self.branch7x7dbl(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 96 + 96 + 96 + 96 = 384 channels\n",
    "\n",
    "class InceptionB_Reduction(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionB_Reduction, self).__init__()\n",
    "    self.branch3x3 = nn.Sequential(\n",
    "      BasicConv2d(channels_in, 96, 1, stride=1, padding=0),\n",
    "      BasicConv2d(96, 160, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch7x7x3 = nn.Sequential(\n",
    "      BasicConv2d(channels_in, 96, 1, stride=1, padding=0),\n",
    "      BasicConv2d(96, 96, (1, 7), stride=1, padding=(0, 3)),\n",
    "      BasicConv2d(96, 96, (7, 1), stride=1, padding=(3, 0)),\n",
    "      BasicConv2d(96, 96, 3, stride=2, padding=1)\n",
    "    )\n",
    "    self.branch_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    outputs = [self.branch3x3(x), self.branch7x7x3(x), self.branch_pool(x)]\n",
    "    return torch.cat(outputs, 1)  # 160 + 96 + channels_in\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "  def __init__(self, channels_in):\n",
    "    super(InceptionC, self).__init__()\n",
    "    self.branch1x1 = BasicConv2d(channels_in, 160, 1, stride=1, padding=0)\n",
    "\n",
    "    self.branch3x3_1 = BasicConv2d(channels_in, 192, 1, stride=1, padding=0)\n",
    "    self.branch3x3_2a = BasicConv2d(192, 192, (1, 3), stride=1, padding=(0, 1))\n",
    "    self.branch3x3_2b = BasicConv2d(192, 192, (3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "    self.branch3x3dbl_1 = nn.Sequential(\n",
    "        BasicConv2d(channels_in, 224, 1, stride=1, padding=0),\n",
    "        BasicConv2d(224, 192, 3, stride=1, padding=1)\n",
    "    )\n",
    "    self.branch3x3dbl_2a = BasicConv2d(192, 192, (1, 3), stride=1, padding=(0, 1))\n",
    "    self.branch3x3dbl_2b = BasicConv2d(192, 192, (3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "    self.branch_pool = nn.Sequential(\n",
    "        nn.AvgPool2d(3, stride=1, padding=1),\n",
    "        BasicConv2d(channels_in, 96, 1, stride=1, padding=0)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    branch1x1 = self.branch1x1(x)\n",
    "\n",
    "    branch3x3 = self.branch3x3_1(x)\n",
    "    branch3x3 = torch.cat([self.branch3x3_2a(branch3x3), self.branch3x3_2b(branch3x3)], 1)\n",
    "\n",
    "    branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "    branch3x3dbl = torch.cat([self.branch3x3dbl_2a(branch3x3dbl), self.branch3x3dbl_2b(branch3x3dbl)], 1)\n",
    "\n",
    "    branch_pool = self.branch_pool(x)\n",
    "\n",
    "    outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "    return torch.cat(outputs, 1)  # 160 + 384 + 384 + 96 = 1024 channels\n",
    "      \n",
    "class ModifiedInception_C(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ModifiedInception_C, self).__init__()\n",
    "    self.in_block = nn.Sequential(\n",
    "      BasicConv2d(1, 16, 3, stride=2, padding=0),\n",
    "      BasicConv2d(16, 32, 3, stride=1, padding=0),\n",
    "      BasicConv2d(32, 32, 3, stride=1, padding=1),\n",
    "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "      BasicConv2d(32, 40, 3, stride=1, padding=0),\n",
    "      BasicConv2d(40, 96, 3, stride=1, padding=1),\n",
    "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    )\n",
    "    self.mix_block = nn.Sequential(\n",
    "      InceptionA(96, 16),\n",
    "      InceptionA(128, 32),\n",
    "      InceptionA(144, 32),\n",
    "      InceptionA_Reduction(144),\n",
    "      InceptionB(384, 64),\n",
    "      InceptionB(384, 80),\n",
    "      InceptionB(384, 80),\n",
    "      InceptionB(384, 96),\n",
    "      InceptionB_Reduction(384),\n",
    "      InceptionC(640),\n",
    "      InceptionC(1024),\n",
    "    )\n",
    "    self.out_block = nn.Sequential(\n",
    "      nn.AdaptiveAvgPool2d(1),\n",
    "      nn.Dropout(0.2)\n",
    "    )\n",
    "    self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.in_block(x)\n",
    "    x = self.mix_block(x)\n",
    "    x = self.out_block(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4285317e-282e-42bc-9557-832af4a9535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:47<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.0498, Train Accuracy: 62.83%, Test Loss: 0.7420, Test Accuracy: 71.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:45<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.6453, Train Accuracy: 77.01%, Test Loss: 0.5501, Test Accuracy: 81.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.5140, Train Accuracy: 82.48%, Test Loss: 0.4307, Test Accuracy: 84.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:47<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.4317, Train Accuracy: 85.19%, Test Loss: 0.3943, Test Accuracy: 86.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3896, Train Accuracy: 86.64%, Test Loss: 0.3991, Test Accuracy: 84.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.3581, Train Accuracy: 87.64%, Test Loss: 0.3288, Test Accuracy: 88.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.3326, Train Accuracy: 88.52%, Test Loss: 0.3916, Test Accuracy: 86.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.3085, Train Accuracy: 89.46%, Test Loss: 0.3093, Test Accuracy: 89.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.2924, Train Accuracy: 89.75%, Test Loss: 0.2984, Test Accuracy: 89.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [01:46<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.2787, Train Accuracy: 90.38%, Test Loss: 0.3005, Test Accuracy: 89.03%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 1066.0327453613281 s\n"
     ]
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "learning_rate = 0.005\n",
    "num_epochs = 10\n",
    "\n",
    "ModifiedInceptionModel_C = ModifiedInception_C().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ModifiedInceptionModel_C.parameters(), lr=learning_rate)\n",
    "\n",
    "train(ModifiedInceptionModel_C, criterion, optimizer, num_epochs, inception_train_loader, inception_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37323c-a233-49c8-b34d-7e112aeb6210",
   "metadata": {},
   "source": [
    "---\n",
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44831a6-3586-44b3-a29a-ecdb792e054b",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02c1e9ac-0891-4046-9781-fc4be87ae3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/UG/chua0994/.cache/torch/hub/pytorch_vision_v0.7.0\n",
      "100%|██████████| 1875/1875 [05:55<00:00,  5.28it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6592, Train Accuracy: 77.74%, Test Loss: 0.3884, Test Accuracy: 86.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:55<00:00,  5.28it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4084, Train Accuracy: 85.13%, Test Loss: 0.3411, Test Accuracy: 87.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:55<00:00,  5.27it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.5393, Train Accuracy: 83.97%, Test Loss: 0.3472, Test Accuracy: 87.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:55<00:00,  5.27it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.3519, Train Accuracy: 87.47%, Test Loss: 0.3073, Test Accuracy: 88.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:54<00:00,  5.29it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3033, Train Accuracy: 89.01%, Test Loss: 0.2885, Test Accuracy: 89.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:53<00:00,  5.30it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.3618, Train Accuracy: 88.62%, Test Loss: 0.3243, Test Accuracy: 88.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:53<00:00,  5.31it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.3883, Train Accuracy: 88.02%, Test Loss: 0.2806, Test Accuracy: 89.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:53<00:00,  5.31it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.2824, Train Accuracy: 89.71%, Test Loss: 0.2957, Test Accuracy: 89.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:53<00:00,  5.30it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.2676, Train Accuracy: 90.32%, Test Loss: 0.2930, Test Accuracy: 89.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:53<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.2654, Train Accuracy: 90.32%, Test Loss: 0.2881, Test Accuracy: 89.52%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 3543.9587218761444 s\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "PretrainedVGGModel = vgg16(weights=VGG16_Weights.DEFAULT).to(device)\n",
    "\n",
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PretrainedVGGModel.parameters(), lr=learning_rate)\n",
    "\n",
    "train(PretrainedVGGModel, criterion, optimizer, num_epochs, vgg_channel_train_loader, vgg_channel_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac03e9-f4b7-4968-b3a9-7020a63984f4",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0103a72a-1500-417f-b277-2fe9cf20b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:47<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3462, Train Accuracy: 87.88%, Test Loss: 0.2795, Test Accuracy: 89.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:46<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2351, Train Accuracy: 91.66%, Test Loss: 0.2259, Test Accuracy: 92.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:46<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.1964, Train Accuracy: 92.94%, Test Loss: 0.2056, Test Accuracy: 92.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:47<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1717, Train Accuracy: 93.86%, Test Loss: 0.1899, Test Accuracy: 93.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:46<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1434, Train Accuracy: 94.82%, Test Loss: 0.1904, Test Accuracy: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:45<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1146, Train Accuracy: 95.87%, Test Loss: 0.1987, Test Accuracy: 93.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:45<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0888, Train Accuracy: 96.76%, Test Loss: 0.1955, Test Accuracy: 94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:45<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0635, Train Accuracy: 97.75%, Test Loss: 0.2241, Test Accuracy: 93.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [03:45<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0495, Train Accuracy: 98.19%, Test Loss: 0.2703, Test Accuracy: 92.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [04:25<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0395, Train Accuracy: 98.56%, Test Loss: 0.2895, Test Accuracy: 93.22%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 2302.2743515968323 s\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "PretrainedResNetModel = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "\n",
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PretrainedResNetModel.parameters(), lr=learning_rate)\n",
    "\n",
    "train(PretrainedResNetModel, criterion, optimizer, num_epochs, inception_channel_train_loader, inception_channel_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791a75c-5fa8-4312-b98e-2d3e2705ba48",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "261d4095-b7d8-482a-bc80-287f2bcd5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/UG/chua0994/.cache/torch/hub/pytorch_vision_v0.7.0\n",
      "100%|██████████| 1875/1875 [06:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3688, Train Accuracy: 87.24%, Test Loss: 0.2656, Test Accuracy: 90.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2514, Train Accuracy: 91.20%, Test Loss: 0.2228, Test Accuracy: 92.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2141, Train Accuracy: 92.45%, Test Loss: 0.1988, Test Accuracy: 93.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:03<00:00,  5.16it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1881, Train Accuracy: 93.30%, Test Loss: 0.2186, Test Accuracy: 92.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1670, Train Accuracy: 94.10%, Test Loss: 0.2732, Test Accuracy: 90.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:02<00:00,  5.18it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1453, Train Accuracy: 94.88%, Test Loss: 0.1810, Test Accuracy: 93.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [06:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.1264, Train Accuracy: 95.48%, Test Loss: 0.1786, Test Accuracy: 93.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:56<00:00,  5.26it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.1086, Train Accuracy: 96.04%, Test Loss: 0.1774, Test Accuracy: 94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:58<00:00,  5.24it/s]\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0920, Train Accuracy: 96.62%, Test Loss: 0.2234, Test Accuracy: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [05:57<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0753, Train Accuracy: 97.28%, Test Loss: 0.1996, Test Accuracy: 94.35%\n",
      "\n",
      "\n",
      "Total Time Elapsed: 3610.4280977249146 s\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "PretrainedInceptionModel = inception_v3(weights=Inception_V3_Weights.DEFAULT).to(device)\n",
    "\n",
    "# defining hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(PretrainedInceptionModel.parameters(), lr=learning_rate)\n",
    "\n",
    "train(PretrainedInceptionModel, criterion, optimizer, num_epochs, inception_channel_train_loader, inception_channel_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
